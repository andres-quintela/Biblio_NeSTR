@article{Arulkumaran2017ALearning,
    title = {{A Brief Survey of Deep Reinforcement Learning}},
    year = {2017},
    journal = {IEEE Signal Processing Magazine},
    author = {Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
    url = {https://spiral.imperial.ac.uk/bitstream/10044/1/53340/2/1708.05866v1.pdf},
    arxivId = {1708.05866v1}
}

@article{Bellemare2017ALearning,
    title = {{A Distributional Perspective on Reinforcement Learning}},
    year = {2017},
    author = {Bellemare, Marc G. and Dabney, Will and Munos, Rémi},
    month = {7},
    url = {http://arxiv.org/abs/1707.06887},
    arxivId = {1707.06887}
}

@article{Tan2018ALearning,
    title = {{A Survey on Deep Transfer Learning}},
    year = {2018},
    author = {Tan, Chuanqi and Sun, Fuchun and Kong, Tao and Zhang, Wenchang and Yang, Chao and Liu, Chunfang},
    month = {8},
    url = {http://arxiv.org/abs/1808.01974},
    arxivId = {1808.01974}
}

@article{Parisotto2015Actor-Mimic:Learning,
    title = {{Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning}},
    year = {2015},
    author = {Parisotto, Emilio and Ba, Jimmy Lei and Salakhutdinov, Ruslan},
    month = {11},
    url = {http://arxiv.org/abs/1511.06342},
    arxivId = {1511.06342}
}

@article{ROBINS1995CatastrophicInterferenceStabilityPlasticityRehearsal.,
    title = {{Catastrophic Forgetting;Catastrophic Interference;Stability;Plasticity;Rehearsal.}},
    year = {1995},
    journal = {Connection Science},
    author = {ROBINS, ANTHONY},
    number = {2},
    month = {6},
    pages = {123--146},
    volume = {7},
    url = {http://www.tandfonline.com/doi/abs/10.1080/09540099550039318},
    doi = {10.1080/09540099550039318},
    issn = {0954-0091}
}

@techreport{RobinsConsolidationBrain,
    title = {{Consolidation in Neural Networks and in the Sleeping Brain}},
    author = {Robins, Anthony},
    url = {https://pdfs.semanticscholar.org/b793/83adbbdf3e97780f7c149b20d038e2aeb4ad.pdf}
}

@article{Zenke2017ContinualIntelligence,
    title = {{Continual Learning Through Synaptic Intelligence}},
    year = {2017},
    author = {Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
    month = {3},
    url = {http://arxiv.org/abs/1703.04200},
    arxivId = {1703.04200}
}

@article{Parisi2018ContinualReview,
    title = {{Continual Lifelong Learning with Neural Networks: A Review}},
    year = {2018},
    author = {Parisi, German I. and Kemker, Ronald and Part, Jose L. and Kanan, Christopher and Wermter, Stefan},
    month = {2},
    url = {http://arxiv.org/abs/1802.07569},
    arxivId = {1802.07569}
}

@article{Lillicrap2015ContinuousLearning,
    title = {{Continuous control with deep reinforcement learning}},
    year = {2015},
    author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
    month = {9},
    url = {http://arxiv.org/abs/1509.02971},
    arxivId = {1509.02971}
}

@article{Meeter2003ControlEffects,
    title = {{Control of consolidation in neural networks: Avoiding runaway effects}},
    year = {2003},
    journal = {Connection Science},
    author = {Meeter, Martijn},
    number = {1},
    month = {3},
    pages = {45--61},
    volume = {15},
    publisher = { Taylor {\&} Francis Group },
    url = {http://www.tandfonline.com/doi/abs/10.1080/0954009031000149591},
    doi = {10.1080/0954009031000149591},
    issn = {0954-0091},
    keywords = {Catastrophic Interference, Consolidation, Pseudorehearsal, Rehearsal}
}

@article{vanHasselt2015DeepQ-learning,
    title = {{Deep Reinforcement Learning with Double Q-learning}},
    year = {2015},
    author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
    month = {9},
    url = {http://arxiv.org/abs/1509.06461},
    arxivId = {1509.06461}
}

@article{vanHasselt2015DeepQ-learningb,
    title = {{Deep Reinforcement Learning with Double Q-learning}},
    year = {2015},
    author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
    month = {9},
    url = {http://arxiv.org/abs/1509.06461},
    arxivId = {1509.06461}
}

@techreport{SilverDeterministicAlgorithms,
    title = {{Deterministic Policy Gradient Algorithms}},
    author = {Silver, David and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
    url = {http://proceedings.mlr.press/v32/silver14.pdf}
}

@article{Dewangan2018DiGrad:Actions,
    title = {{DiGrad: Multi-Task Reinforcement Learning with Shared Actions}},
    year = {2018},
    author = {Dewangan, Parijat and Phaniteja, S and Krishna, K Madhava and Sarkar, Abhishek and Ravindran, Balaraman},
    month = {2},
    url = {http://arxiv.org/abs/1802.10463},
    arxivId = {1802.10463}
}

@article{Teh2017Distral:Learning,
    title = {{Distral: Robust Multitask Reinforcement Learning}},
    year = {2017},
    author = {Teh, Yee Whye and Bapst, Victor and Czarnecki, Wojciech Marian and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
    month = {7},
    url = {http://arxiv.org/abs/1707.04175},
    arxivId = {1707.04175}
}

@techreport{TutunovDistributedConvergence,
    title = {{Distributed Multitask Reinforcement Learning with Quadratic Convergence}},
    author = {Tutunov, Rasul and Kim, Dongho and Bou-Ammar, Haitham},
    url = {https://papers.nips.cc/paper/8106-distributed-multitask-reinforcement-learning-with-quadratic-convergence.pdf}
}

@article{Wang2015DuelingLearning,
    title = {{Dueling Network Architectures for Deep Reinforcement Learning}},
    year = {2015},
    author = {Wang, Ziyu and Schaul, Tom and Hessel, Matteo and van Hasselt, Hado and Lanctot, Marc and de Freitas, Nando},
    month = {11},
    url = {http://arxiv.org/abs/1511.06581},
    arxivId = {1511.06581}
}

@article{Mnih2015Human-levelLearning,
    title = {{Human-level control through deep reinforcement learning}},
    year = {2015},
    journal = {Nature},
    author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
    url = {https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf},
    doi = {10.1038/nature14236}
}

@techreport{YinKnowledgeReplay,
    title = {{Knowledge Transfer for Deep Reinforcement Learning with Hierarchical Experience Replay}},
    author = {Yin, Haiyan and Jialin Pan, Sinno},
    url = {www.aaai.org},
    keywords = {Machine Learning Applications}
}

@article{Parisotto2017NeuralLearning,
    title = {{Neural Map: Structured Memory for Deep Reinforcement Learning}},
    year = {2017},
    author = {Parisotto, Emilio and Salakhutdinov, Ruslan},
    month = {2},
    url = {http://arxiv.org/abs/1702.08360},
    arxivId = {1702.08360}
}

@article{Kirkpatrick2017OvercomingNetworks.,
    title = {{Overcoming catastrophic forgetting in neural networks.}},
    year = {2017},
    journal = {Proceedings of the National Academy of Sciences of the United States of America},
    author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
    number = {13},
    month = {3},
    pages = {3521--3526},
    volume = {114},
    publisher = {National Academy of Sciences},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/28292907 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5380101},
    doi = {10.1073/pnas.1611835114},
    issn = {1091-6490},
    pmid = {28292907},
    keywords = {artificial intelligence, continual learning, deep learning, stability plasticity, synaptic consolidation}
}

@techreport{MnihPlayingLearning,
    title = {{Playing Atari with Deep Reinforcement Learning}},
    author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
    url = {https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf}
}

@techreport{RusuPOLICYDISTILLATION,
    title = {{POLICY DISTILLATION}},
    author = {Rusu, Andrei A and Colmenarejo, Sergio Gómez and A˘ Glar G ¨ Ul{\c{c}}ehre, C ¸ and Desjardins, Guillaume and Kirkpatrick, James and Pascanu, Razvan and Mnih, Volodymyr and Kavukcuoglu, Koray and Hadsell, Raia},
    url = {https://arxiv.org/pdf/1511.06295.pdf},
    arxivId = {1511.06295v2}
}

@article{Schaul2015PrioritizedReplay,
    title = {{Prioritized Experience Replay}},
    year = {2015},
    author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
    month = {11},
    url = {http://arxiv.org/abs/1511.05952},
    arxivId = {1511.05952}
}

@article{Schaul2015PrioritizedReplayb,
    title = {{Prioritized Experience Replay}},
    year = {2015},
    author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
    month = {11},
    url = {http://arxiv.org/abs/1511.05952},
    arxivId = {1511.05952}
}

@article{Hessel2017Rainbow:Learning,
    title = {{Rainbow: Combining Improvements in Deep Reinforcement Learning}},
    year = {2017},
    author = {Hessel, Matteo and Modayil, Joseph and van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
    month = {10},
    url = {https://arxiv.org/abs/1710.02298},
    arxivId = {1710.02298}
}

@misc{GoogleRegularizationDevelopers,
    title = {{Regularization for Simplicity: L₂ Regularization  |  Machine Learning Crash Course  |  Google Developers}},
    author = {{Google}},
    url = {https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/l2-regularization}
}

@book{Sutton1998ReinforcementIntroduction,
    title = {{Reinforcement Learning: An Introduction}},
    year = {1998},
    author = {Sutton, Richard S and Barto, Andrew G},
    publisher = {MIT Press},
    url = {http://incompleteideas.net/book/bookdraft2017nov5.pdf}
}

@techreport{Bellemare2013TheAgents,
    title = {{The Arcade Learning Environment: An Evaluation Platform for General Agents}},
    year = {2013},
    booktitle = {Journal of Artificial Intelligence Research},
    author = {Bellemare, Marc G and Veness, Joel and Bowling, Michael},
    pages = {253--279},
    volume = {47},
    url = {http://stella.sourceforge.net/},
    arxivId = {1207.4708v2}
}

@misc{TrentRolls-Royce,
    title = {{Trent 1000 – Rolls-Royce}},
    url = {https://www.rolls-royce.com/products-and-services/civil-aerospace/airlines/trent-1000.aspx#/}
}

@article{McClelland1995WhyMemory.,
    title = {{Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory.}},
    year = {1995},
    journal = {Psychological review},
    author = {McClelland, J L and McNaughton, B L and O'Reilly, R C},
    number = {3},
    month = {7},
    pages = {419--57},
    volume = {102},
    url = {http://www.ncbi.nlm.nih.gov/pubmed/7624455},
    issn = {0033-295X},
    pmid = {7624455}
}